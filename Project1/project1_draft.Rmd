---
title: 'Predictive Analysis Project1 : Forecasting'
author: Jered Ataky, Matthew Baker, Christopher Bloome, David Blumenstiel, Dhairav
  Chhatbar
date: "6/25/2021"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Libraries
```{r, warning = FALSE, message=FALSE}
library(dplyr)
library(forecast)
library(readxl)
library(skimr)
library(tidyr)
library(dplyr)
library(seasonal)
library(ggfortify)
library(urca)
library(forecast)
library(aTSA)

```

## Data Exploration & Preparation

### The data

Read the excel file

```{r, message=FALSE, warning=FALSE}
url<-"https://github.com/jnataky/Predictive_Analytics/raw/main/Project1/Data_Set_for_Class.xls"
temp.file <- paste(tempfile(),".xls",sep = "")
download.file(url, temp.file, mode = "wb")

dataset <- read_excel(temp.file, sheet = 1)

```



Converting the series index to date format:
Assuming that the data represent stock data, we are going to convert 
the series index in date using 1990-01-02 as reference to allow us to have
only week days which will make sense for stock data.
```{r}
df <- dataset %>%
  mutate(SeriesInd = as.Date(SeriesInd, origin="1900-01-02"))
head(df)
```

```{r}
df %>%
  group_by(group) %>%
  summarise(var1_NAsum = sum(is.na(Var01)),
            var2_NAsum = sum(is.na(Var02)),
            var3_NAsum = sum(is.na(Var03)),
            var5_NAsum = sum(is.na(Var05)),
            var7_NAsum = sum(is.na(Var07)))
```

Missing data i
s distributed within the same observations for the most part.  Group has negligable effect on missing values.  
There are about 140 missing observations per group which are the number to forecast.
Drop NA Values
```{r}
df <- df %>% gather("Var", "Value", 3:7) %>% drop_na()
```

### Visulizations

```{r, fig.width=15, fig.height=20}

df$Day <- weekdays(df$SeriesInd)
df %>% ggplot( aes(x=SeriesInd, y=Value, color=group))  + facet_wrap(~Var, scales = "free", ncol = 1) + geom_line() +
  labs(title = "Var Trends by Groups") 
```

```{r, message=FALSE, warning=FALSE}
day_summary <- df %>% select(group, Var, Day) %>% group_by(group, Var, Day) %>% summarise(Days=n()) 
day_summary %>% ggplot( aes(fill=group, y=Days, x=Day)) + geom_bar(position="dodge", stat="identity") + facet_wrap(~Var, scales = "free", ncol = 2) + 
  labs(title="Day Distribution")
```


Nearly uniform but has consistant slight differences across variables



### Time series

Separating data by group to make different time series

#### S01 Var01
```{r, warning=FALSE}
S01_Var01 <- ts(df %>% filter(group == "S01", Var=="Var01") %>% select(Value), frequency = 1)
autoplot(S01_Var01)


Acf(S01_Var01)
Pacf(S01_Var01, lag.max = 10) 

adf.test(S01_Var01) #Unit root test.  This tests if differencing is nessiary
ndiffs(S01_Var01) #Determines how many first differences are nessicary

#Differenced acf/pacf plots

Acf(diff(S01_Var01), lag.max = 10)
Pacf(diff(S01_Var01), lag.max = 10) 


```

non-stationary; trend
needs 1 first differencing

suggestive of autoregressive process because the PACF becomes insignificant much earlier than the ACF

Both the ACF and PACF of the differenced series start positive, and become insignificant after lag 2.  Could be two MA and two AR terms; maybe more AR terms because the PACF starts positive.





#### S01 Var02
```{r, warning=FALSE}
S01_Var02 <- ts(df %>% filter(group == "S01", Var=="Var02") %>% select(Value), frequency = 1)
autoplot(S01_Var02)

Acf(S01_Var02)
pacf(S01_Var02)

adf.test(S01_Var02) #Unit root test.  This tests if differencing is nessiary
ndiffs(S01_Var02) #Determines how many first differences are nessicary

#Differenced acf/pacf plots

Acf(diff(S01_Var02), lag.max = 10)
Pacf(diff(S01_Var02), lag.max = 10) 


```

stationary

needs 1 first differencing
 

suggestive of autoregressive process

The ACF of the differenced series the ACF of the differenced series cuts off more quickly than the PACF, indicating primarily AR.  The ACF cuts off past lag 2, and the PACF takes a while.  Could try several AR terms and fewer MA terms




#### S02 Var02
```{r, warning=FALSE}
S02_Var02 <- ts(df %>% filter(group == "S02", Var=="Var02") %>% select(Value), frequency = 1)
autoplot(S02_Var02)

Acf(S02_Var02)
Pacf(S02_Var02)

adf.test(S02_Var02) #Unit root test.  This tests if differencing is nessiary
ndiffs(S02_Var02) #Determines how many first differences are nessicary

#Differenced acf/pacf plots

Acf(diff(S02_Var02), lag.max = 10)
Pacf(diff(S02_Var02), lag.max = 10) 

```

stationary

needs 1 first differencing
 
suggestive of autoregressive process

The ACF of the differenced series the ACF of the differenced series cuts off more quickly than the PACF, indicating primarily AR.  The ACF cuts off past lag 2, and the PACF takes a while.  Could try several AR terms and fewer MA terms


#### S02 Var03
```{r, warning=FALSE}
S02_Var03 <- ts(df %>% filter(group == "S02", Var=="Var03") %>% select(Value), frequency = 1) %>% tsclean()
autoplot(S02_Var03)



Acf(S02_Var03)
Pacf(S02_Var03, lag.max = 10)

adf.test(S02_Var03) #Unit root test.  This tests if differencing is nessiary
ndiffs(S02_Var03) #Determines how many first differences are nessicary

#Differenced acf/pacf plots

Acf(diff(S02_Var03), lag.max = 10)
Pacf(diff(S02_Var03), lag.max = 10) 

```

A nice big outlier here.  It was removed with tsclean()

Not stationary; maybe not trend?

needs 1 first differencing

suggestive of autoregressive process

ACF of the differenced series cuts off from a negative value very quickly, indicating AR process.  It takes a while for the PACF of the differenced series to drop off, so a higher order AR process.  ACF is negative, so maybe an MA term would work well in addition.


#### S03 Var05
```{r, warning=FALSE}
S03_Var05 <- ts(df %>% filter(group == "S03", Var=="Var05") %>% select(Value), frequency = 1)
autoplot(S03_Var05)

Acf(S03_Var05)
Pacf(S03_Var05, lag.max = 10)

adf.test(S03_Var05) #Unit root test.  This tests if differencing is nessiary
ndiffs(S03_Var05) #Determines how many first differences are nessicary

#Differenced acf/pacf plots

Acf(diff(S03_Var05), lag.max = 10)
Pacf(diff(S03_Var05), lag.max = 10) 

```

non-stationary; trend 

needs 1 first differencing

suggestive of autoregressive process

Both PACF and ACF of the differenced series cut off after 1 lag.  Maybe one MA and AR term


#### S03 Var07
```{r, warning=FALSE}
S03_Var07 <- ts(df %>% filter(group == "S03", Var=="Var07") %>% select(Value), frequency = 1)
autoplot(S03_Var07)

Acf(S03_Var07)
Pacf(S03_Var07, lag.max = 10)

adf.test(S03_Var07) #Unit root test.  This tests if differencing is nessiary
ndiffs(S03_Var07) #Determines how many first differences are nessicary


Acf(diff(S03_Var07), lag.max = 10)
Pacf(diff(S03_Var07), lag.max = 10) 

```

non-stationary; trend and

needs 1 first differencing

suggestive of autoregressive process

No significant lags in either ACF of PACF of the differenced series.  This one has no AR or MA terms


#### S04 Var01
```{r, warning=FALSE}
S04_Var01 <- ts(df %>% filter(group == "S04", Var=="Var01") %>% select(Value), frequency = 1)
autoplot(S04_Var01) 

Acf(S04_Var01)
Pacf(S04_Var01, lag.max = 10)

adf.test(S04_Var01) #Unit root test.  This tests if differencing is nessiary
ndiffs(S04_Var01) #Determines how many first differences are nessicary

Acf(diff(S04_Var01), lag.max = 10)
Pacf(diff(S04_Var01), lag.max = 10) 


```

non-stationary; trend

needs 1 first difference

suggestive of autoregressive process

No significant lags in either ACF of PACF of the differenced series.  This one has no AR or MA terms



#### S04 Var02
```{r, warning=FALSE}
S04_Var02 <- ts(df %>% filter(group == "S04", Var=="Var02") %>% select(Value), frequency = 1)
autoplot(S04_Var02) 

Acf(S04_Var02)
Pacf(S04_Var02, lag.max = 10)

adf.test(S04_Var02) #Unit root test.  This tests if differencing is nessiary
ndiffs(S04_Var02) #Determines how many first differences are nessicary


Acf(diff(S04_Var02), lag.max = 10)
Pacf(diff(S04_Var02), lag.max = 10) 


```

Stationary

needs 1 first difference

suggestive of autoregressive process, but less so than others

A high number of significant lags in the PACF of the differenced series, and a few significant lags in the ACF.  Probably a higher number of AR terms, maybe a couple MA terms


#### S05 Var02
```{r, warning=FALSE}
S05_Var02 <- ts(df %>% filter(group == "S01", Var=="Var01") %>% select(Value), frequency = 1)
autoplot(S05_Var02)

Acf(S05_Var02)
Pacf(S05_Var02)

adf.test(S05_Var02) #Unit root test.  This tests if differencing is nessiary
ndiffs(S05_Var02) #Determines how many first differences are nessicary

Acf(diff(S05_Var02), lag.max = 10)
Pacf(diff(S05_Var02), lag.max = 10) 


```

non-stationary; trend 

needs 1 first difference

suggestive of autoregressive process

Similar ACF and PACF of differenced series.  Maybe one of each term, or two AR because PACF starts positive


#### S05 Var03
```{r, warning=FALSE}
S05_Var03 <- ts(df %>% filter(group == "S05", Var=="Var03") %>% select(Value), frequency = 1)
autoplot(S05_Var03)

Acf(S05_Var03)
Pacf(S05_Var03)

adf.test(S05_Var03) #Unit root test.  This tests if differencing is nessiary
ndiffs(S05_Var03) #Determines how many first differences are nessicary


Acf(diff(S05_Var03), lag.max = 10)
Pacf(diff(S05_Var03), lag.max = 10) 

```

non-stationary (probably); probably trend

needs 1 first difference

suggestive of autoregressive process

Similar ACF and PACF of differenced series.  Maybe one of each term, or two AR because PACF starts positive



#### S06 Var05

```{r, warning=FALSE}
S06_Var05 <- ts(df %>% filter(group == "S06", Var=="Var05") %>% select(Value), frequency = 1) %>% tsclean()
autoplot(S06_Var05)

Acf(S06_Var05)
Pacf(S06_Var05)

adf.test(S06_Var05) #Unit root test.  This tests if differencing is nessiary
ndiffs(S06_Var05) #Determines how many first differences are nessicary

Acf(diff(S06_Var05), lag.max = 10)
Pacf(diff(S06_Var05), lag.max = 20) 

```

needed outlier cleaning

non-stationary

needs 1 first  difference

suggestive of autoregressive process

The ACF of the differenced series cut off after 1 lag, while the PACF trailed on for a while.  Could be just one MA term, maybey 2


#### S06 Var07
```{r, warning=FALSE}
S06_Var07 <- ts(df %>% filter(group == "S06", Var=="Var07") %>% select(Value), frequency = 1) %>% tsclean()
autoplot(S06_Var07) 

Acf(S06_Var07)
Pacf(S06_Var07)

adf.test(S06_Var07) #Unit root test.  This tests if differencing is nessiary
ndiffs(S06_Var07) #Determines how many first differences are nessicary

Acf(diff(S06_Var07), lag.max = 10)
Pacf(diff(S06_Var07), lag.max = 20) 

```

needed outlier cleaning

non-stationary

needs 1 first  difference

suggestive of autoregressive process


The ACF of the differenced series cut off after 1 lag, while the PACF trailed on for a while.  Could be just one MA term, maybey 2


## Modeling

This was of great help: https://www.datalytyx.com/choosing-the-right-forecast-model-for-time-series-data/

Also this for helping determine the number of AR/MA terms: https://people.duke.edu/~rnau/arimrule.htm

We'll try selecting ARIMA models based on our observations of the data, and by using the auto.arima() function to find one automatically.

When it comes to testing for correlations among residuals, we'll use Box-Ljung tests.  We'll use ln(n) as the number of lags, where n is the number of residuals.  There's not much consensus out there on how many lags to use (pretty sure R automatically uses the frequency, but this isn't great), but hopefully this'l do.


Note: because all datasets indicate 1 differencing is appropriate, d (the 'I' in arima) is always going to be 1.  Could do ARMA models on the differenced timeseries, but ARIMA saves some code.  




##### Some common observations:

Everything seems to require differencing 1 time. 

No seasonal differencing was nessicariry; likely no seasonal trends



### S01 Var01

Both the ACF and PACF of the differenced series start positive, and become insignificant after lag 2.  Could be two MA and two AR terms; maybe more AR terms because the PACF starts positive.

#### Manual

We'll try out ARIMA 2, 1, 1.  There is a trend, so drift should be included

```{r}
#First a little function.  Takes an arima model and does the analyses/residual-visualizations
arima_analysis <- function(fit) {
  print(summary(fit))
  
  checkresiduals(fit, lag = log(length(fit$residuals)))
}
```


```{r}
S01_Var01.fit <- Arima(S01_Var01, order = c(2, 1, 1), include.drift = TRUE)

arima_analysis(S01_Var01.fit)



```

The residuals have a mean of approximately 0 and are distributed normally.  However they might not vary constantly, and the acf plot indicates some autocorrelation.  The Ljung-Box test however failed to find evidence that the observed autocrorrelations did not come from white noise.  This is a valid model

#### Auto ARIMA

```{r}
S01_Var01.autofit <- auto.arima(S01_Var01)

arima_analysis(S01_Var01.autofit)

```

the auto.arima function came up with ARIMA 0, 1, 2 with drift; much heavier on moving average than the manually selected model, with no autoregressive term.

The residuals have a mean of approximately 0 and are distributed normally.  However they might not vary constantly, and the acf plot indicates some autocorrelation.  The Ljung-Box test however failed to find evidence that the observed autocrorrelations did not come from white noise.  This is a valid model.

Both models perform similarly, with the manual model barely edging out the automatic one with a log liklihood 0.04 higher, although the AICc for the auto model is slightly smaller.  The RMSE for the manual model was also negligably higher.  Either model works, but the reasoning behind the manual one makes more sense (should have autoregressive terms according to ACF/PACF of differenced series)


### S01 Var02

#### Manual

The ACF of the differenced series the ACF of the differenced series cuts off more quickly than the PACF, indicating primarily AR.  The ACF cuts off past lag 2, and the PACF takes a while.  Could try several AR terms and fewer MA terms

We'll go with ARIMA 3,1,1 with no drift

```{r}
S01_Var02.fit <- Arima(S01_Var02, order = c(3, 1, 1), include.drift = FALSE)

arima_analysis(S01_Var02.fit)

qqnorm(S01_Var02.fit$residuals)
qqline(S01_Var02.fit$residuals)
```

ARIMA 3, 1, 1 yielded some significantly correlated residuals, indicating this model isn't a great fit.  QQplot and the historgram indicate that the residuals are not normally distributed.  Let's see how an automatic fit does.

#### automatic

```{r}
S01_Var02.autofit <- auto.arima(S01_Var02)

arima_analysis(S01_Var02.autofit)

qqnorm(S01_Var02.autofit$residuals)
qqline(S01_Var02.autofit$residuals)
```

This doesn't do well either.  let's try a log transform and do again

#### Log transform automatic

```{r}
S01_Var02.autofit <- auto.arima(log(S01_Var02))

arima_analysis(S01_Var02.autofit)

qqnorm(S01_Var02.autofit$residuals)
qqline(S01_Var02.autofit$residuals)
```

Much better.  Residuals here have a normal distribution with a mean of approximately 0.  Box-Ljung test found insignificant correlation between residuals.  QQ looks acceptable.

Use this one, but make sure to account for the log transform.

### S02 Var02

#### Manual

The ACF of the differenced series the ACF of the differenced series cuts off more quickly than the PACF, indicating primarily AR.  The ACF cuts off past lag 2, and the PACF takes a while.  Could try several AR terms and fewer MA terms

We'll go with ARIMA 3,1,1 with no drift


```{r}
S02_Var02.fit <- Arima(S02_Var02, order = c(3, 1, 1), include.drift = FALSE)

arima_analysis(S02_Var02.fit)

```

Ljung-Box finds the residuals to be correlated.  Let's see what automatic does

#### Automatic

```{r}
S02_Var02.autofit <- auto.arima(S02_Var02)

arima_analysis(S02_Var02.autofit)

```

Not gonna do it.  Let's try a log transform again.

#### Second manual with log transform 

```{r}
S02_Var02.fit <- Arima(log(S02_Var02), c(1,1,4))

arima_analysis(S02_Var02.fit)

qqnorm(S02_Var02.fit$residuals)
qqline(S02_Var02.fit$residuals)
```

Auto arima here wasn't cutting it, even with the log transform.  ARIMA 1, 1, 4 on the log transformed data seems a good balance between maximizing log liklihood, and minimizing AICc.  Use this one.

### S02 Var03

#### Manual

ACF of the differenced series cuts off from a negative value very quickly, indicating AR process.  It takes a while for the PACF of the differenced series to drop off, so a higher order AR process.  ACF is negative, so maybe an MA term would work well in addition.

We'll go with ARIMA 2, 1, 1 with drift

```{r}
S02_Var03.fit <- Arima(S02_Var03, order = c(2, 1, 1), include.drift = TRUE)

arima_analysis(S02_Var03.fit)

autoplot(tsclean(S02_Var03))

```

There is significant correlation between residuals.  Let's try automatic.

#### Automatic

```{r}
S02_Var03.autofit <- auto.arima(S02_Var03)

arima_analysis(S02_Var03.autofit)

```

Slightly worse AICc and log likelihood, but tecnically insignificant correlation between residuals.  That being said, it's pretty close.  Could try a log transformation.

#### automatic with log transformation

```{r}
S02_Var03.autofit <- auto.arima(log(S02_Var03))

arima_analysis(S02_Var03.autofit)

```

Less significant correlation between residuals, but now the other statistics don't compare with the previous models.  Make of this what you will.  

### S03 Var05

#### Manual

Both PACF and ACF of the differenced series cut off after 1 lag.  Maybe one MA and AR term with no drift

```{r}
S03_Var05.fit <- Arima(S03_Var05, order = c(1, 1, 1), include.drift = FALSE)

arima_analysis(S03_Var05.fit)

```

Fits well.

#### Automatic

```{r}
S03_Var05.autofit <- auto.arima(S03_Var05)

arima_analysis(S03_Var05.autofit)


```

Similar ARIMA 1, 1, 1 does slighly better in terms of log liklihood but slightly worse in AIC.  Go with ARIMA 1, 1, 1 (manual)?

### S03 Var07

#### Manual

No significant lags in either ACF of PACF of the differenced series.  This one has no AR or MA terms

```{r}
S03_Var07.fit <- Arima(S03_Var07, order = c(0, 1, 0), include.drift = FALSE)

arima_analysis(S03_Var07.fit)



```

#### Automatic

```{r}
S03_Var07.autofit <- auto.arima(S03_Var07)

arima_analysis(S03_Var07.autofit)

```

Automatic does the same thing.  Go with either (theyre literally the same model)

### S04 Var01

#### Manual

No significant lags in either ACF of PACF of the differenced series.  This one has no AR or MA terms

```{r}
S04_Var01.fit <- Arima(S04_Var01, order = c(0, 1, 0), include.drift = FALSE)

arima_analysis(S04_Var01.fit)

```

#### Automatic

```{r}
S04_Var01.autofit <- auto.arima(S04_Var01)

arima_analysis(S04_Var01.autofit)

```

Same story: go with either model (they're both the same)

### S04 Var02

#### Manual

A high number of significant lags in the PACF of the differenced series, and a few significant lags in the ACF.  Probably a higher number of AR terms, maybe a couple MA terms

```{r}
S04_Var02.fit <- Arima(S04_Var02, order = c(4, 1, 2), include.drift = FALSE)

arima_analysis(S04_Var02.fit)

qqnorm(S04_Var02.fit$residuals)
qqline(S04_Var02.fit$residuals)
```

Insignificant correlation betwen residuals, but the residuals are skewed.  Let's try again with a log transform.

#### Manual with log transformation

```{r}
S04_Var02.fit <- Arima(log(S04_Var02), order = c(4, 1, 2), include.drift = FALSE)

arima_analysis(S04_Var02.fit)

qqnorm(S04_Var02.fit$residuals)
qqline(S04_Var02.fit$residuals)
```

Definitely a better model.  We'll try an automatic fit with log transformation for comparison.

#### Automatic with log transformation

```{r}
S04_Var02.autofit <- auto.arima(log(S04_Var02))

arima_analysis(S04_Var02.autofit)

qqnorm(S04_Var02.fit$residuals)
qqline(S04_Var02.fit$residuals)
```

Automatic here has correlated residuals.  The manual model (ARIMA 4, 1, 2 no drift) of the log transformed time series does better on in terms of log likelihood and AICc, along with having no significant correlations among residuals.  Use the Manual ARIMA model with the log transformation


### S05 Var02

#### Manual

Similar ACF and PACF of differenced series.  Maybe one of each term, or two AR because PACF starts positive

```{r}
S05_Var02.fit <- Arima(S05_Var02, order = c(2, 1, 1), include.drift = FALSE)

arima_analysis(S05_Var02.fit)

```

Works.  Looks good.

#### Automatic

```{r}
S05_Var02.autofit <- auto.arima(S05_Var02)

arima_analysis(S05_Var02.autofit)

```

This automatic model (ARIMA 0, 1, 2 with drift) works better than the manual one.  Has Higher log likelihood and lower AICc.  Use this one.

### S06 Var05
 
#### Manual

The ACF of the differenced series cut off after 1 lag, while the PACF trailed on for a while.  Could be just one MA term, maybey 2

```{r}
S06_Var05.fit <- Arima(S06_Var05, order = c(0, 1, 2), include.drift = FALSE)

arima_analysis(S06_Var05.fit)

```

Has correlated residuals.  No bueno.

#### Automatic

```{r}
S06_Var05.autofit <- auto.arima(S06_Var05)

arima_analysis(S06_Var05.autofit)

```

Better.  No correlated residuals.  Use this one.


### S06 Var07

#### Manual

The ACF of the differenced series cut off after 1 lag, while the PACF trailed on for a while.  Could be just one MA term, maybey 2

```{r}
S06_Var07.fit <- Arima(S06_Var07, order = c(0, 1, 2), include.drift = FALSE)

arima_analysis(S06_Var07.fit)

```

Works, but only just.  Technically insignificant correlation between residuals, but..

#### Automatic

```{r}
S06_Var07.autofit <- auto.arima(S06_Var07)

arima_analysis(S06_Var07.autofit)

```

Much better.  Use this one.


